<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="https://bruhtus.github.io/scrawl/feed.xml" rel="self" type="application/atom+xml" /><link href="https://bruhtus.github.io/scrawl/" rel="alternate" type="text/html" /><updated>2021-01-26T18:35:56-06:00</updated><id>https://bruhtus.github.io/scrawl/feed.xml</id><title type="html">Bruhtus’ Scrawl</title><subtitle>Unstable Explanation</subtitle><entry><title type="html">Tiling Window Manager For Efficiency</title><link href="https://bruhtus.github.io/scrawl/linux/english/2020/10/15/tiling-window-manager.html" rel="alternate" type="text/html" title="Tiling Window Manager For Efficiency" /><published>2020-10-15T00:00:00-05:00</published><updated>2020-10-15T00:00:00-05:00</updated><id>https://bruhtus.github.io/scrawl/linux/english/2020/10/15/tiling-window-manager</id><content type="html" xml:base="https://bruhtus.github.io/scrawl/linux/english/2020/10/15/tiling-window-manager.html">&lt;h2 id=&quot;before-we-start-a-brief-explanation-about-window-manager&quot;&gt;Before We Start, A Brief Explanation About Window Manager&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;A window manager is a system software that controls the placement and appearance of windows within a windowing system in a graphical user interface (GUI). It can be part of desktop enviroment (DE) or be used standalone&lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;So basically window manager is how to place a window. There’re three types of window manager (according to arch wiki&lt;sup id=&quot;fnref:1:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;): stacking (aka floating) window manager, tiling window manager, and dynamic window manager.&lt;/p&gt;

&lt;p&gt;Here’s a brief explanation about those three window manager:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Stacking (aka floating) Window Manager:
All window manager that allow the overlapping of windows are considered stacking window manager, although it is possible that not all stacking window manager use the same method. You can check a few list of stacking window manager &lt;a href=&quot;https://wiki.archlinux.org/index.php/window_manager#Stacking_window_managers&quot;&gt;here&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;Tiling Window Manager:
Tiling window manager manage the window so that no window are overlapping with each other. You can check a few list of tiling window manager &lt;a href=&quot;https://wiki.archlinux.org/index.php/window_manager#Tiling_window_managers&quot;&gt;here&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;Dynamic Window Manager:
Dynamic window manager is a tiling window manager that positioned based on the preset layouts which user can switch. You can check a few list of dynamic window manager &lt;a href=&quot;https://wiki.archlinux.org/index.php/window_manager#Dynamic_window_managers&quot;&gt;here&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For more detailed comparision of tiling window manager, you can check &lt;a href=&quot;https://wiki.archlinux.org/index.php/Comparison_of_tiling_window_managers&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;the-window-manager-ive-tried&quot;&gt;The Window Manager I’ve Tried&lt;/h2&gt;

&lt;p&gt;For now (at the times of writing this post), i only have tried 2 window manager. My first window manager is qtile and my second window manager is i3. You can check below for more (not really) detailed explanation(?).&lt;/p&gt;

&lt;h3 id=&quot;i3-window-manager&quot;&gt;i3 Window Manager&lt;/h3&gt;
&lt;p&gt;i3 is one of tiling type window manager, for more info you can check at &lt;a href=&quot;https://i3wm.org/&quot;&gt;their website&lt;/a&gt;. I’m just gonna explain configuration that i’ve made at my &lt;a href=&quot;https://github.com/bruhtus/i3_config&quot;&gt;github repo&lt;/a&gt;. For the record, this is my current window manager (at the time writing this post). I’m using the manjaro i3 edition.&lt;/p&gt;

&lt;p&gt;First of all, i changed the mod keybinding from super key (or some people call it windows key) to alt key. You can change the mod keybinding by change &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;set $mod Mod4&lt;/code&gt; (super key) to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;set $mod Mod1&lt;/code&gt; (alt key) in config file (you can find config file in folder &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.i3&lt;/code&gt;). For the most part i used the default config from manjaro i3 edition but i add a few program and even changed the i3 status bar with polybar. Here’s what i used in this config:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/dylanaraps/pywal&quot;&gt;pywal&lt;/a&gt;: I use this for color scheme around my i3 environment (such as terminal, border color around window, etc)&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/polybar/polybar&quot;&gt;polybar&lt;/a&gt;: I use this to replace i3 status bar because i can place the clock and date in the middle (i have no ide how to do that in i3 status bar or even py3status) and it has quite a lot of customization. You can also use py3status if you want.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/davatorium/rofi&quot;&gt;rofi&lt;/a&gt;: I use this as application manager instead of dmenu, because it’s more convenient for me (rofi appear in the middle meanwhile dmenu appear at the top).&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/brndnmtthws/conky&quot;&gt;conky&lt;/a&gt;: I use this to take a glance what process currently taking up resources (for more detailed info i use htop).&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/flameshot-org/flameshot&quot;&gt;flameshot&lt;/a&gt;: I use this to take screenshot.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;setting-up-keybinding&quot;&gt;Setting Up Keybinding&lt;/h4&gt;
&lt;p&gt;For setting up keybinding you can use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bindsym&lt;/code&gt;, for example: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bindsym $mod+q kill&lt;/code&gt; for close focused or currenly active window. Other than setting up keybindings, you can also set a program to do a certain thing, for example: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;set $myTerm alacritty&lt;/code&gt;, every thing that used $myTerm gonna access the command via terminal alacritty. Alacritty is my current (at the time of typing this post) terminal emulator, i also have xterm as a backup terminal emulator. Example of using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;$myTerm&lt;/code&gt;: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bindsym $mod+e exec $myTerm -e ranger&lt;/code&gt; to open ranger file manager.&lt;/p&gt;

&lt;h4 id=&quot;setting-up-polybar&quot;&gt;Setting Up Polybar&lt;/h4&gt;
&lt;p&gt;For setting up polybar, you need to move the default polybar config. In my case, the default config is in /usr/share/doc/polybar/ but if it’s not there, you can use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;locate polybar | grep config&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;First of all, make a polybar folder in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.config&lt;/code&gt; folder. After that move the default polybar config into those folder (the path should be like this &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.config/polybar/config&lt;/code&gt;). You can change the default config to anything you want, but remember the bar name because we’re gonna use the bar name to launch the polybar. The default bar name should be like this &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;[bar/example]&lt;/code&gt;, you can change it to the name you want and please specify the monitor for the polybar. You can check you monitor name by typing &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;xrandr&lt;/code&gt; on terminal. Here’s an example how to set a monitor in polybar config: &lt;br /&gt;&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;After i typed &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;xrandr&lt;/code&gt; on my terminal, i got my laptop screen name &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;eDP-1&lt;/code&gt; so i’m gonna use my laptop screen to display the polybar.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[bar/mainbar-i3]

monitor = {env:MONITOR:eDP-1}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;After you’re done with your polybar config, the next step is to add launch.sh. What is launch.sh? well, it’s basically to launch all of our polybar bar config (that has this naming scheme &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;[bar/example]&lt;/code&gt;). Here’s an example of launch.sh in two monitor (each bar config has different monitor assigned to it):&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#!/usr/bin/bash

#Terminate already running bar instances
killall -q polybar

#Wait until the process have been shut down
while pgrep -u $UID -x polybar &amp;gt;/dev/null; do
    sleep i; done

#launch bar
polybar mainbar-i3 &amp;amp;
polybar secondbar-i3 &amp;amp;

echo &quot;bars launched...&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;who-should-try-or-use-i3&quot;&gt;Who Should Try or Use i3?&lt;/h4&gt;
&lt;p&gt;i3 is a ‘manual’ tiling window manager so it doesn’t really have default layout which is different from dynamic ‘tiling’ window manager, you need to specify where the window opened (whether the window opened on the right or below). If you want to use i3 you might want to consider that. So, who should try or use i3? everyone who wants a tiling window manager and  doesn’t really mind to have manually control where the window appear, that’s all.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;qtile-window-manager&quot;&gt;Qtile Window Manager&lt;/h3&gt;
&lt;p&gt;Qtile is one of dynamic window manager that use python as basis configuration, for more info you can check at &lt;a href=&quot;https://qtile.org/&quot;&gt;their website&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In my &lt;a href=&quot;https://github.com/bruhtus/qtile_config&quot;&gt;config repo&lt;/a&gt; i usually use MonadTall layout or Max layout. MonadTall layout basically split the first two window into half vertically and then for the third and so on gonna split the right window horisontally. Max layout basically have the application automatically take up the whole screen, that’s all. For more build-in layouts you can check their documentation &lt;a href=&quot;http://docs.qtile.org/en/latest/manual/ref/layouts.html?highlight=layouts&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I used qtile window manager first before switch to i3 because the configuration is in python but what i don’t really like is how qtile treat multiple screen. When i want to switch to second monitor, it swapped the application on second monitor to first monitor (currently active monitor) and that’s not what i want, i just want to switch to different screen and not have application on that screen swapped with application on my currently active screen. It was confusing and then i tried i3wm after that.&lt;/p&gt;

&lt;p&gt;The config in my repo is a basic config i’ve done because i don’t really like the workflow of qtile. Sorry about that.&lt;/p&gt;

&lt;h4 id=&quot;who-should-try-or-use-qtile&quot;&gt;Who Should Try or Use Qtile?&lt;/h4&gt;
&lt;p&gt;If you’re fine with the workflow of qtile, wants to try or use dynamic window manager, like to have or doesn’t really mind  preconfigured layout, and have experience with python then you might want to try qtile. Don’t get me wrong, qtile is good as a window manager but unfortunately it doesn’t meet my needs.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;the-pros-and-cons-of-tiling-window-manager&quot;&gt;The Pros and Cons of Tiling Window Manager&lt;/h2&gt;
&lt;p&gt;Pros:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;You don’t have to worry about placement of your window because it’s automatically split the workplace for you.&lt;/li&gt;
  &lt;li&gt;You use mouse less.&lt;/li&gt;
  &lt;li&gt;All your application is right there without any overlap window.
    &lt;blockquote&gt;
      &lt;p&gt;Surprise, you haven’t close me yet so i’m gonna take up your computer resources.&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Cons:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;If you open too much application then the application size gonna become smaller. (that’s why use virtual desktop or workspace 1 to 8).&lt;/li&gt;
  &lt;li&gt;It’s kind of hard to setting for first time. After that hard time, you can backup your previous config and use it again in other computer. Nice.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;to-wrap-things-up&quot;&gt;To Wrap Things Up&lt;/h2&gt;
&lt;p&gt;If you want to use keyboard-oriented navigation or you don’t want to use mouse often, then you probably should try using tiling window manager. But, as i’ve mentioned above, it took time to learn how to configure it (and i think it’s worth your time).&lt;/p&gt;

&lt;p&gt;If you’re still not sure, you can try it first in virtual machine (such as virtualbox or virt-manager) and then you could copy those config file to your new installation.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;example-of-i3-window-manager&quot;&gt;Example of i3 Window Manager&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Moderate use: &lt;br /&gt;
&lt;img src=&quot;/scrawl/images/window-manager/example-of-i3wm.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Too much window in one workspace can be bad: &lt;br /&gt;
&lt;img src=&quot;/scrawl/images/window-manager/too-much-window.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;footnotes&quot;&gt;Footnotes&lt;/h2&gt;
&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://wiki.archlinux.org/index.php/window_manager&quot;&gt;Arch linux wiki (window manager)&lt;/a&gt;. &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt; &lt;a href=&quot;#fnref:1:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name></name></author><category term="Linux" /><category term="English" /><summary type="html">Before We Start, A Brief Explanation About Window Manager</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://bruhtus.github.io/scrawl/images/window-manager/i3wm-logo.png" /><media:content medium="image" url="https://bruhtus.github.io/scrawl/images/window-manager/i3wm-logo.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Pavement Distress Detector Using Single Shot Detector (SSD)</title><link href="https://bruhtus.github.io/scrawl/deep%20learning/english/2020/10/11/pavement-distress-ssd.html" rel="alternate" type="text/html" title="Pavement Distress Detector Using Single Shot Detector (SSD)" /><published>2020-10-11T00:00:00-05:00</published><updated>2020-10-11T00:00:00-05:00</updated><id>https://bruhtus.github.io/scrawl/deep%20learning/english/2020/10/11/pavement-distress-ssd</id><content type="html" xml:base="https://bruhtus.github.io/scrawl/deep%20learning/english/2020/10/11/pavement-distress-ssd.html">&lt;h2 id=&quot;before-we-start-heres-a-diagram-process-of-this-project&quot;&gt;Before We Start, Here’s a Diagram Process of This Project&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/scrawl/images/pavement-distress-ssd/diagram-process.png&quot; alt=&quot;&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;a-brief-explanation-about-single-shot-detector-ssd&quot;&gt;A Brief Explanation About Single Shot Detector (SSD)&lt;/h2&gt;

&lt;p&gt;Single shot detector is a deep learning method presented by Wei Liu, Dragomir Anguelov, Dumitru Erhan, Christian Szegedy, Scott Reed4, Cheng-Yang Fu, Alexander C. Berg in their research paper &lt;a href=&quot;https://arxiv.org/abs/1512.02325&quot;&gt;SSD: Single Shot Multibox Detector&lt;/a&gt;. There are 2 commonly used SSD model, that is, SSD300 and SSD512.
&lt;br /&gt;
Here’s a brief explanation about SSD300 and SSD512:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;SSD300: More fast.&lt;/li&gt;
  &lt;li&gt;SSD512: More accurate.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Long story short, SSD300 is about speed. If you need speed than you should probably use SSD300 (i haven’t tried the mobilenet as base network at the time to type this, so at this time knowledge SSD300 is faster than SSD512). Meanwhile, SSD512 is about accuracy. It doesn’t really show up in image processing but in video processing, i notice that there’s a frame rate drop while doing live object detection. To be fair, SSD300 has frame rate drop as well but it’s still usable (around 7-10 frame per second) but SSD512 has frame rate around 3-5 frame per second. 
Who want to watch a video with 3 fps?? If you’re that kind of person then, go ahead. You do you mate.&lt;/p&gt;

&lt;p&gt;For the record, at that time when I try live detection, i use opencv to display live detection video. i’m not sure whether it is opencv fault or the model fault because if I save the video result, the video itself has no frame rate drop. It’s weird but it happens, so let’s go on with saving the video and forget about live detection (for now, until i find some way to do live detection).&lt;/p&gt;

&lt;p&gt;So, in this project i’m not gonna make it live detection. Rather than live detections, we’re gonna save the video result first and then display it later. That way it could also reduce some computational cost.&lt;/p&gt;

&lt;p&gt;For those who still confused about live detection, to make things simpler, live detection is when you process the video, detect the object, and play the video at the same time. After you detect the object, you immediately display the frame that just recently processed and then processed the next frame. Repeat.&lt;/p&gt;

&lt;h3 id=&quot;single-shot-detector-ssd-architecture-thats-used-in-this-project&quot;&gt;Single Shot Detector (SSD) Architecture That’s Used in This Project&lt;/h3&gt;
&lt;p&gt;As explained above, in this project we’re gonna use SSD512. SSD512 is basically SSD with input image 512x512. The basic architecture of SSD contains 2 part, base network and extra feature layers. The base network layers are based on standard architecture used for high quality image classification (truncated before classification layers). The extra feature layers used for multi-scale feature maps for detection and convolutional predictors for detection.&lt;/p&gt;

&lt;p&gt;Here is an architecture single shot detector that used in this project (made this with &lt;a href=&quot;http://alexlenail.me/NN-SVG/AlexNet.html&quot;&gt;NN architecture maker&lt;/a&gt;):
&lt;img src=&quot;/scrawl/images/pavement-distress-ssd/ssd-architecture.png&quot; alt=&quot;&quot; /&gt;&lt;br /&gt;
Information:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Input image.&lt;/li&gt;
  &lt;li&gt;Base Network (truncated before classification layers).&lt;/li&gt;
  &lt;li&gt;Layer 6 and layer 7 of base network (from fully-connected layer turned into classification layer).&lt;/li&gt;
  &lt;li&gt;Extra feature layers.&lt;/li&gt;
  &lt;li&gt;Collection of boxes and scores.&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;base-network&quot;&gt;Base Network&lt;/h4&gt;
&lt;p&gt;The base network used in this project is Visual Geometry Group (VGG). I chose VGG because of transfer learning capability so that i could have a good result with small dataset. To be more specific, in this project i used VGG16, here is a brief explanation of each layers:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;In the first layer, there’s a convolutional process with kernel filter 3x3 and stride (total shift filter per pixel) 1 pixel. That process repeat 2 times and then did some max pooling with kernel filter 2x2 and stride 2 pixel.&lt;/li&gt;
  &lt;li&gt;In the second layer until fourth layer, the model did the same thing as in first layer.&lt;/li&gt;
  &lt;li&gt;The difference was in fifth layer. In fifth layer, the convolution process still the same as the other four layers but the max pooling process was different from the other four layers. The max pooling process used kernel filter 3x3 with stride 1 pixel with padding (adding zero value around pixel image) 1. You can check the illustration below to understand the process of max pooling with kernel filter 3x3, stride 1, and padding 1. &lt;br /&gt;
&lt;img src=&quot;/scrawl/images/pavement-distress-ssd/max-pooling-illustration.png&quot; alt=&quot;&quot; /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;And here’s a VGG16 after truncated from classification layers: &lt;br /&gt;
&lt;img src=&quot;/scrawl/images/pavement-distress-ssd/truncated-vgg16.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;If you want to calculate the result from max polling, you can use this equation &lt;sup id=&quot;fnref:2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;: &lt;br /&gt;
&lt;img src=&quot;/scrawl/images/pavement-distress-ssd/max-pooling-equation.png&quot; alt=&quot;&quot; /&gt;&lt;br /&gt;
Information:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;kernel_size, stride, padding, and dilation can be 1 integer (in this case, the value for height and width are the same) or 2 integer (in this case, the first integer is height and the second integer is width).&lt;/li&gt;
  &lt;li&gt;For more info you can see &lt;a href=&quot;https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html&quot;&gt;pytorch page&lt;/a&gt;.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Here’s some example of max pooling calculation with input 32x32, kernel filter 3x3, stride 1, padding 1, and dilation 1: &lt;br /&gt;
&lt;img src=&quot;/scrawl/images/pavement-distress-ssd/max-pooling-calculation.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;layer-6-and-layer-7&quot;&gt;Layer 6 and Layer 7&lt;/h4&gt;
&lt;p&gt;After feature extraction process in base network, the next layers is to change layer 6 and 7 of base network from fully-connected into convolutional layer with subsample parameters from fully-connected 6 (fc6) and fully-connected 7 (fc7). The convolution operation used in layer 6 and layer 7 is atrous convolution, you can see atrous convolution shift below: &lt;br /&gt;
&lt;img src=&quot;/scrawl/images/pavement-distress-ssd/atrous-convolution.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;With atrous convolution we can expand area of observation for feature extraction while maintaning the amount of parameters fewer than traditional convolution operation.&lt;/p&gt;

&lt;h4 id=&quot;extra-feature-layers&quot;&gt;Extra Feature Layers&lt;/h4&gt;
&lt;p&gt;Extra feature layers is a prediction layers. In this layer, the model predict the object using default box. Default box is a box with various aspect ratio in every location of feature maps with different size. You can see an example of default box below &lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; &lt;br /&gt;
&lt;img src=&quot;/scrawl/images/pavement-distress-ssd/default-box.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In the last layer is a collection of default boxes which closer to ground truth box with confidence score from that default boxes.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;take-a-video-training-video-and-testing-video&quot;&gt;Take A Video (Training Video and Testing Video)&lt;/h2&gt;

&lt;p&gt;In this part, i’m gonna explain about the video used in this project. The camera configuration, the place where the video taken, the camera angle and height from the road.&lt;/p&gt;

&lt;p&gt;The place where the video taken was in Surabaya, at Kertajaya Indah Timur IX, Kertajaya Indah Timur X, and Kertajaya Indah Timur XI. The camera angle was perpendicular(?) with the road (90 degrees) and the camera position from the road was 200 cm.&lt;/p&gt;

&lt;p&gt;There’re 7 video taken, 3 for training and 4 for testing. The format of the video was &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;*.mp4&lt;/code&gt;. You can check the location partition of the video taken below: &lt;br /&gt;
&lt;img src=&quot;/scrawl/images/pavement-distress-ssd/video-taken.jpg&quot; alt=&quot;&quot; /&gt;&lt;br /&gt;
The black block is for testing and the white block is for training. You can check the position of the camera below: &lt;br /&gt;
&lt;img src=&quot;/scrawl/images/pavement-distress-ssd/camera-position.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;setting-up-the-config-file&quot;&gt;Setting Up The Config File&lt;/h2&gt;

&lt;p&gt;For more detailed configuration please check &lt;a href=&quot;https://github.com/lufficc/SSD/blob/master/DEVELOP_GUIDE.md&quot;&gt;develop guide by Congcong Li&lt;/a&gt;. In this post i’m gonna explain it the easiest way.&lt;/p&gt;

&lt;h3 id=&quot;basic-configuration&quot;&gt;Basic Configuration&lt;/h3&gt;
&lt;p&gt;To make things easier, copy the format dataset you want. For example, in this project i want to use COCO dataset format. Then, i copied the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;coco.py&lt;/code&gt; in the path &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ssd/data/datasets/&lt;/code&gt; and rename it to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;my_dataset.py&lt;/code&gt;. After that, edit the class names for your classification class. In this project, the class i’m gonna use is alligator crack, longitudinal crack, transverse crack, and pothole. Also, don’t forget to change the class &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;COCODataset&lt;/code&gt; to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;MyDataset&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;The next step is to add those configuration to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;__init__.py&lt;/code&gt; in ssd/data/datasets/. For example:&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;.my_dataset&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MyDataset&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;_DATASETS&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'VOCDataset'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;VOCDataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'COCODataset'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;COCODataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'MyDataset'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MyDataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Another next step is to add the path of your datasets and anotations to the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;path_catlog.py&lt;/code&gt; in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ssd/config/&lt;/code&gt;. For example:&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;os&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;DatasetCatalog&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;DATA_DIR&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'datasets'&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;DATASETS&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;'my_custom_train_dataset'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;&quot;data_dir&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;train&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;&quot;ann_file&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;annotations/train.json&quot;&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;

        &lt;span class=&quot;s&quot;&gt;'my_custom_validation_dataset'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;&quot;data_dir&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;validation&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;&quot;ann_file&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;annotations/validation.json&quot;&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    
    &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;staticmethod&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;my_custom_train_dataset&quot;&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;my_custom_train_dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DatasetCatalog&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DATA_DIR&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;attrs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DatasetCatalog&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DATASETS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;data_dir&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;my_custom_train_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attrs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'data_dir'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]),&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;ann_file&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;my_custom_train_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attrs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'ann_file'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]),&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;factory&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;MyDataset&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

         &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;my_custom_test_dataset&quot;&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;my_custom_train_dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DatasetCatalog&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DATA_DIR&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;attrs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DatasetCatalog&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DATASETS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;data_dir&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;my_custom_train_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attrs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'data_dir'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]),&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;ann_file&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;my_custom_train_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attrs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'ann_file'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]),&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;factory&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;MyDataset&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And finally, for the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;*.yaml&lt;/code&gt; file for configuration i copied &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;vgg_ssd512_coco_trainval35k.yaml&lt;/code&gt; in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;configs&lt;/code&gt; folder and rename it to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;config.yaml&lt;/code&gt;. What i changed from that file was the train and test (or more like validation) like in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;path_catlog.py&lt;/code&gt;, the batch size, and num_classes. I changed batch size because my laptop gpu only capable of 4 batch size. Here’s an example:&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;Model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;num_classes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;#the __background__ counted
&lt;/span&gt;    &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;DATASETS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;TRAIN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;my_custom_train_dataset&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;TEST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;my_custom_test_dataset&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;SOLVER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;BATCH_SIZE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;OUTPUT_DIR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'outputs/ssd_custom_coco_format'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;You don’t need to create folder &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ssd_custom_coco_format&lt;/code&gt;, when the training begin the folder gonna created automatically (if the folder didn’t exist).&lt;/p&gt;

&lt;h3 id=&quot;validation-configuration&quot;&gt;Validation Configuration&lt;/h3&gt;
&lt;p&gt;First of all, copy &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;coco&lt;/code&gt; folder in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ssd/data/datasets/evaluation/&lt;/code&gt; and rename it to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;my_dataset&lt;/code&gt;. Rename the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;def coco_evaluation&lt;/code&gt; to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;def my_dataset_evaluation&lt;/code&gt; in file &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;__init__.py&lt;/code&gt;. After that, add folder &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;my_dataset&lt;/code&gt; to file &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;__init__.py&lt;/code&gt; in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ssd/data/datasets/evaluation/&lt;/code&gt;. For example:&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;ssd.data.datasets&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;VOCDataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;COCODataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MyDataset&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;.my_dataset&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;my_dataset_evaluation&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;evaluate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output_dir&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;isinstance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MyDataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;my_dataset_evaluation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;raise&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NotImplementError&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;training-preparation&quot;&gt;Training Preparation&lt;/h2&gt;

&lt;p&gt;Before training the model, we need to do some preparation. There’re two steps in this process, frame extraction and labeling. Without further ado, let’s get started.&lt;/p&gt;

&lt;h3 id=&quot;frame-extraction&quot;&gt;Frame Extraction&lt;/h3&gt;
&lt;p&gt;In this process, i used python library &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;opencv&lt;/code&gt; to extract some frame. Here’s the script:&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;cv2&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;time&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;fire&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Fire&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tqdm&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tqdm&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;video_file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;path_save&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;speed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# the lower the speed the fastest the frame_rates, speed = 0 (pause)
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;vidcap&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cv2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;VideoCapture&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;video_file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;current_frame&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;speed_frame&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;speed&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vidcap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;isOpened&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()):&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;success&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;frame&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vidcap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# success = retrival value for frame 
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;length&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vidcap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cv2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CAP_PROP_FRAME_COUNT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; 
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;f'Current Frame: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;current_frame&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;current_frame&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; 

        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;success&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;cv2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;imshow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Video'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cv2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;waitKey&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;speed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;mh&quot;&gt;0xFF&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ord&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'s'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# press s to save the frame
&lt;/span&gt;                &lt;span class=&quot;n&quot;&gt;cv2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;imwrite&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;f&quot;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path_save&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;/frame_&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;current_frame&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;.jpg&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

            &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cv2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;waitKey&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;speed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;mh&quot;&gt;0xFF&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ord&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'q'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# press q to quit
&lt;/span&gt;                &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;

            &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cv2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;waitKey&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;speed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;mh&quot;&gt;0xFF&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ord&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'w'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# play/pause
&lt;/span&gt;                &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;speed&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;speed&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;speed&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;speed&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;speed_frame&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;vidcap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;release&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;cv2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;destroyAllWindows&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;__name__&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'__main__'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Fire&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Every time we press &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;s&lt;/code&gt;, it’s gonna take the current frame at that time. For the speed, i usually go for 25 but if you want slower you could change it to 10 or lower (as long as it’s not 0, please).&lt;/p&gt;

&lt;p&gt;After the extraction process, i have 652 images/frames for training process. The 652 images/frames have this proportion (There’re a few object in one frame):&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Pavement Distress&lt;/th&gt;
      &lt;th&gt;Object&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Alligator Crack&lt;/td&gt;
      &lt;td&gt;367&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Longitudinal Crack&lt;/td&gt;
      &lt;td&gt;951&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Transverse Crack&lt;/td&gt;
      &lt;td&gt;243&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Potholes&lt;/td&gt;
      &lt;td&gt;161&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;labeling&quot;&gt;Labeling&lt;/h3&gt;
&lt;p&gt;For the labeling i use labelme, you could check the tutorial &lt;a href=&quot;https://www.dlology.com/blog/how-to-create-custom-coco-data-set-for-instance-segmentation/&quot;&gt;here&lt;/a&gt; and to change labelme format to coco dataset format &lt;a href=&quot;https://github.com/Tony607/labelme2coco&quot;&gt;here&lt;/a&gt;. There’s nothing much to explain about labeling, you just give box to an object and save with the label you want. So, let’s move on.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;here-we-go-its-training-time&quot;&gt;Here We Go, It’s Training Time!&lt;/h2&gt;

&lt;p&gt;For the training process i use google colaboratory (how to use google colaboratory is beyond this post, sorry) but you could also use other services such as &lt;a href=&quot;https://www.paperspace.com/?utm_expid=.XZhCPCNrQCuE1jH9t8bIgg.0&amp;amp;utm_referrer=&quot;&gt;paperspace&lt;/a&gt;. Here’s an example of command line if you use you local machine or cloud services: &lt;br /&gt;
Local: &lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;python train.py &lt;span class=&quot;nt&quot;&gt;--config-file&lt;/span&gt; configs/config.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Cloud: &lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;!python train.py --config-file configs/config.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Basically there’s no difference so i think it’s not that difficult, good luck.&lt;/p&gt;

&lt;h3 id=&quot;loss-function-graph&quot;&gt;Loss Function Graph&lt;/h3&gt;
&lt;p&gt;As the training begin, please don’t forget to check the loss function. The closer the loss function to zero the better but be carefull so that it doesn’t overfitting (a model memorized the training data and have difficulty predicting the testing data). Here’s the unscientific tips from me, stop the training process if you don’t see any improvement in loss function. For example, if the loss function stuck at 0.9 - 0.5 for quite some time then you should stop the process. Here’s my loss function graph: &lt;br /&gt;
&lt;img src=&quot;/scrawl/images/pavement-distress-ssd/loss-function-graph.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;testing-preparation&quot;&gt;Testing Preparation&lt;/h2&gt;

&lt;p&gt;Before testing the model, there’re a few things we need to do:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Copy or move video you want to use into folder &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;input&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;Copy or move configuration file (*.yaml) into folder &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;configs&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;Copy or move folder that has training result into folder &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;outputs&lt;/code&gt; (in this project the folder name is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ssd_custom_coco_format&lt;/code&gt;). The folder name must be the same as in configuration file &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;OUTPUT_DIR&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;If every file and folder in the right places, then let’s move on.&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;go-get-them-the-pavement-distresses-its-testing-time&quot;&gt;Go Get Them (The Pavement Distresses)! It’s Testing Time!&lt;/h2&gt;

&lt;p&gt;For this project, there’s a problem with the counting. Because i have no idea how to implement tracking so i made the counting in the iteration frame (detection at every frame, which is insane) and that’s makes the total counting more than the actual object. To fix this problem (kind of), i do the counting for every 20 frames. The reason was because at every 20 frames, the object detected was closer to the total of actual object than every 10, 15, 25, and 30 frames. So, for the evaluation i’m gonna evaluate the detection result every 20 frames. Thanks.&lt;/p&gt;

&lt;h3 id=&quot;a-brief-showcase-and-explanation-of-the-results&quot;&gt;A Brief Showcase and Explanation of The Results&lt;/h3&gt;
&lt;p&gt;Below is the result:&lt;/p&gt;

&lt;h4 id=&quot;video-testing-1&quot;&gt;Video Testing 1&lt;/h4&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Class Name&lt;/th&gt;
      &lt;th&gt;Counting Results&lt;/th&gt;
      &lt;th&gt;Actual Objects&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Alligator Crack&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Longitudinal Crack&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;29&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Transverse Crack&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;11&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Potholes&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Class Name&lt;/th&gt;
      &lt;th&gt;True Positive&lt;/th&gt;
      &lt;th&gt;True Negative&lt;/th&gt;
      &lt;th&gt;False Positive&lt;/th&gt;
      &lt;th&gt;False Negative&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Alligator Crack&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;11&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Longitudinal Crack&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;25&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Transverse Crack&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Potholes&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;12&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h4 id=&quot;video-testing-2&quot;&gt;Video Testing 2&lt;/h4&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Class Name&lt;/th&gt;
      &lt;th&gt;Counting Results&lt;/th&gt;
      &lt;th&gt;Actual Objects&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Alligator Crack&lt;/td&gt;
      &lt;td&gt;14&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Longitudinal Crack&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Transverse Crack&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Potholes&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Class Name&lt;/th&gt;
      &lt;th&gt;True Positive&lt;/th&gt;
      &lt;th&gt;True Negative&lt;/th&gt;
      &lt;th&gt;False Positive&lt;/th&gt;
      &lt;th&gt;False Negative&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Alligator Crack&lt;/td&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Longitudinal Crack&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Transverse Crack&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Potholes&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h4 id=&quot;video-testing-3&quot;&gt;Video Testing 3&lt;/h4&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Class Name&lt;/th&gt;
      &lt;th&gt;Counting Results&lt;/th&gt;
      &lt;th&gt;Actual Objects&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Alligator Crack&lt;/td&gt;
      &lt;td&gt;21&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Longitudinal Crack&lt;/td&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;15&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Transverse Crack&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Potholes&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Class Name&lt;/th&gt;
      &lt;th&gt;True Positive&lt;/th&gt;
      &lt;th&gt;True Negative&lt;/th&gt;
      &lt;th&gt;False Positive&lt;/th&gt;
      &lt;th&gt;False Negative&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Alligator Crack&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Longitudinal Crack&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;11&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;11&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Transverse Crack&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;14&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Potholes&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;13&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h4 id=&quot;video-testing-4&quot;&gt;Video Testing 4&lt;/h4&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Class Name&lt;/th&gt;
      &lt;th&gt;Counting Results&lt;/th&gt;
      &lt;th&gt;Actual Objects&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Alligator Crack&lt;/td&gt;
      &lt;td&gt;23&lt;/td&gt;
      &lt;td&gt;22&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Longitudinal Crack&lt;/td&gt;
      &lt;td&gt;13&lt;/td&gt;
      &lt;td&gt;46&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Transverse Crack&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;12&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Potholes&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;22&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Class Name&lt;/th&gt;
      &lt;th&gt;True Positive&lt;/th&gt;
      &lt;th&gt;True Negative&lt;/th&gt;
      &lt;th&gt;False Positive&lt;/th&gt;
      &lt;th&gt;False Negative&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Alligator Crack&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;14&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;12&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Longitudinal Crack&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;38&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Transverse Crack&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;22&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Potholes&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;20&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;18&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;From the counting results above we can see that the model struggle to detect longitudinal crack and have a lot of alligator crack detections (detected two times or more). There’re 2 reasons for that, the first is that there’s not enough small-sized longitudinal crack in training dataset and the second is the frame field-of-view too narrow so that a lot of alligator crack devided into different frames and detected multiple times. Here’s an example of that problem: &lt;br /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Undetected Small Longitudinal Crack:
&lt;img src=&quot;/scrawl/images/pavement-distress-ssd/undetected-small-crack.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Multiple Detection of Alligator Crack:
&lt;img src=&quot;/scrawl/images/pavement-distress-ssd/too-much-detection.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And then, we have the precision and recall of the model as below:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Video&lt;/th&gt;
      &lt;th&gt;Precision&lt;/th&gt;
      &lt;th&gt;Recall&lt;/th&gt;
      &lt;th&gt;Accuracy&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Video Testing 1&lt;/td&gt;
      &lt;td&gt;91.43%&lt;/td&gt;
      &lt;td&gt;46.25%&lt;/td&gt;
      &lt;td&gt;60.69%&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Video Testing 2&lt;/td&gt;
      &lt;td&gt;50%&lt;/td&gt;
      &lt;td&gt;36.45%&lt;/td&gt;
      &lt;td&gt;69.58%&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Video Testing 3&lt;/td&gt;
      &lt;td&gt;77.78%&lt;/td&gt;
      &lt;td&gt;69.17%&lt;/td&gt;
      &lt;td&gt;75.45%&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Video Testing 4&lt;/td&gt;
      &lt;td&gt;69.57%&lt;/td&gt;
      &lt;td&gt;24.42%&lt;/td&gt;
      &lt;td&gt;53.81%&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;blockquote&gt;
  &lt;p&gt;At the time of making this post, i’m still not sure whether to use accuracy or f1-score so for now i’m gonna use accuracy.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The difference between video testing 1 to 4 is the total of small-sized pavement distress and video testing 3 has the least total of small-sized pavement distress of all video. So that means, for this trained weight, we obtain the best accuracy when we have the least small-sized pavement distress.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;future-suggestion&quot;&gt;Future Suggestion&lt;/h2&gt;

&lt;p&gt;By no means this is not the best implementation of SSD for pavement distress detection. I have only a few training dataset and a few testing dataset. So you could say what i did here is a minimum requirement that result in minimum performance. You can improve this project quite a lot.&lt;/p&gt;

&lt;p&gt;If you want to improve this project, you can start from these things:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Use a lot of training data and testing data.&lt;/li&gt;
  &lt;li&gt;Use a camera that has wide angle lens (because 50mm lens is not wide enough).&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;side-notes&quot;&gt;Side Notes&lt;/h2&gt;

&lt;p&gt;This is not really important, it’s more like a momento for me. In the undergraduate thesis defence(?) there’s this examiner who has a misconception about testing process and validation process. That examiner switch the possition of testing process as validation process and validation process as testing process, so that really confusing and we have quite an argument there. I even ask in &lt;a href=&quot;https://stats.stackexchange.com/q/484584&quot;&gt;stackexchange&lt;/a&gt; if i’m wrong or not and it turns out that examiner has switch the term for testing and validation. Now i feel stupid for having an argument with that examiner.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;footnotes&quot;&gt;Footnotes&lt;/h2&gt;
&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:2&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html&quot;&gt;Pytorch maxpool2d&lt;/a&gt; &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1512.02325&quot;&gt;SSD: Single Shot Multibox Detector&lt;/a&gt;. &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name></name></author><category term="Deep Learning" /><category term="English" /><summary type="html">Before We Start, Here’s a Diagram Process of This Project</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://bruhtus.github.io/scrawl/images/pavement-distress-ssd/logo.jpg" /><media:content medium="image" url="https://bruhtus.github.io/scrawl/images/pavement-distress-ssd/logo.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>